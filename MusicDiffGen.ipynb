{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d7a4f9",
   "metadata": {},
   "source": [
    "# Install, import and GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9d4c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 4\n",
      "GPU 0: NVIDIA RTX A6000\n",
      "GPU 1: NVIDIA RTX A6000\n",
      "GPU 2: NVIDIA RTX A6000\n",
      "GPU 3: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_gpus = torch.cuda.device_count()  # Get the number of available GPUs\n",
    "print(f\"Number of GPUs: {num_gpus}\")\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b2aecc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyfluidsynth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyfluidsynth\u001b[39;00m\n\u001b[1;32m      2\u001b[0m synth \u001b[38;5;241m=\u001b[39m pyfluidsynth\u001b[38;5;241m.\u001b[39mSynth()\n\u001b[1;32m      3\u001b[0m synth\u001b[38;5;241m.\u001b[39mdelete()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyfluidsynth'"
     ]
    }
   ],
   "source": [
    "import pyfluidsynth\n",
    "synth = pyfluidsynth.Synth()\n",
    "synth.delete()\n",
    "print(\"‚úÖ pyfluidsynth funziona!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11d8a137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: pretty_midi in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (0.2.10)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mido>=1.1.16 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from pretty_midi) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from pretty_midi) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from mido>=1.1.16->pretty_midi) (24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyfluidsynth in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/tesi_giorgio/lib/python3.11/site-packages (from pyfluidsynth) (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyfluidsynth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwavfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m write\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyfluidsynth\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyfluidsynth'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Binomial Diffusion for Symbolic Music Generation with MAESTRO Dataset\n",
    "\n",
    "This script demonstrates:\n",
    "1) How to set up a specific GPU device using the user's code snippet (gpu_id = 1, etc.).\n",
    "2) How to load MAESTRO v3.0.0 from the folder \"DASP/maestro-v3.0.0\", which contains subfolders\n",
    "   (2004, 2006, etc.) and the CSV file \"maestro-v3.0.0.csv\".\n",
    "3) How to build piano-roll segments from the MAESTRO CSV, storing them in a \"MaestroBinomialDiffusionDataset\".\n",
    "4) A UNet-like model named \"MusicDiffusionGenerator\".\n",
    "5) Training and sampling with binomial diffusion on these segments.\n",
    "\n",
    "\"\"\"\n",
    "%pip install torch torchvision torchaudio tqdm pretty_midi pandas\n",
    "%pip install pyfluidsynth\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "from scipy.io.wavfile import write\n",
    "import pyfluidsynth\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 0) Select GPU Device (gpu_id = 1, for example)\n",
    "# --------------------------------------------------------------------------------\n",
    "gpu_id = 1\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "if gpu_id >= num_gpus:\n",
    "    raise ValueError(f\"Invalid GPU ID {gpu_id}. Only {num_gpus} GPUs are available.\")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(gpu_id)\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "print(\"Using GPU:\", torch.cuda.get_device_name(gpu_id))\n",
    "print(\"Device Count:\", torch.cuda.device_count())\n",
    "print(\"Current Device ID:\", torch.cuda.current_device())\n",
    "print(\"CUDA is Available:\", torch.cuda.is_available())\n",
    "\n",
    "device_props = torch.cuda.get_device_properties(gpu_id)\n",
    "print(\"\\n GPU Specifications:\")\n",
    "print(f\"   - Name: {device_props.name}\")\n",
    "print(f\"   - Total Memory: {device_props.total_memory / 1e9:.2f} GB\")\n",
    "print(f\"   - Multiprocessors: {device_props.multi_processor_count}\")\n",
    "print(f\"   - Compute Capability: {device_props.major}.{device_props.minor}\")\n",
    "print(f\"   - Max Threads/MP: {device_props.max_threads_per_multi_processor}\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d07bd",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7578e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1) Build Pianoroll Segments from MAESTRO\n",
    "###############################################################################\n",
    "def midi_to_binary_pianoroll(\n",
    "    midi_path: str,\n",
    "    pitch_low: int = 21,\n",
    "    pitch_high: int = 108,\n",
    "    resolution: int = 24,\n",
    "    segment_beats: int = 16\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a single MIDI file into multiple binary piano-roll segments.\n",
    "    Typically for the full 88-key range: pitch_low=21, pitch_high=108.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray], each shape (T, pitch_range).\n",
    "        E.g. T=384 if segment_beats=16 and resolution=24 => shape=(384, 88).\n",
    "    \"\"\"\n",
    "    print(f\"\\n>>> midi_to_binary_pianoroll: {midi_path}\")\n",
    "    print(f\"    pitch_low={pitch_low}, pitch_high={pitch_high}, resolution={resolution}, segment_beats={segment_beats}\")\n",
    "\n",
    "    try:\n",
    "        pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "        print(\"    Successfully loaded MIDI.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error reading MIDI {midi_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Get a piano roll at 'resolution' frames/sec\n",
    "    piano_roll = pm.get_piano_roll(fs=resolution)  # shape=(128, num_frames)\n",
    "    print(f\"    Raw piano_roll shape: {piano_roll.shape} (128 x frames)\")\n",
    "\n",
    "    # Restrict pitch range\n",
    "    pitch_low = max(0, pitch_low)\n",
    "    pitch_high = min(127, pitch_high)\n",
    "    pr_stripped = piano_roll[pitch_low:pitch_high+1, :]  # shape=(pitch_range, frames)\n",
    "    print(f\"    After pitch restrict => shape: {pr_stripped.shape}\")\n",
    "\n",
    "    # Binarize velocities\n",
    "    pr_stripped = (pr_stripped > 0).astype(np.float32)\n",
    "\n",
    "    # Transpose to (frames, pitch_range)\n",
    "    pr_stripped = pr_stripped.T\n",
    "    print(f\"    Transposed => shape: {pr_stripped.shape} (frames x pitch_range)\")\n",
    "\n",
    "    # frames per segment\n",
    "    frames_per_segment = segment_beats * resolution\n",
    "    total_frames = pr_stripped.shape[0]\n",
    "    num_segments = total_frames // frames_per_segment\n",
    "    print(f\"    frames_per_segment={frames_per_segment}, total_frames={total_frames}, => # segments={num_segments}\")\n",
    "\n",
    "    segments = []\n",
    "    for i in range(num_segments):\n",
    "        start = i * frames_per_segment\n",
    "        end = start + frames_per_segment\n",
    "        seg = pr_stripped[start:end, :]  # shape should be (frames_per_segment, pitch_range)\n",
    "        segments.append(seg)\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "def build_maestro_segments(\n",
    "    maestro_csv: str,\n",
    "    split: str = \"train\",\n",
    "    pitch_low: int = 21,\n",
    "    pitch_high: int = 108,\n",
    "    resolution: int = 24,\n",
    "    segment_beats: int = 16,\n",
    "    base_dir: str = \"maestro-v3.0.0\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a large list of piano-roll segments by scanning the official MAESTRO CSV,\n",
    "    excluding any segment that doesn't have pitch_range=88.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== build_maestro_segments ===\")\n",
    "    print(f\"  Reading CSV: {maestro_csv}\")\n",
    "    print(f\"  Target split: {split}\")\n",
    "    print(f\"  pitch_low={pitch_low}, pitch_high={pitch_high}, resolution={resolution}, segment_beats={segment_beats}\")\n",
    "    print(f\"  base_dir={base_dir}\\n\")\n",
    "\n",
    "    df = pd.read_csv(maestro_csv)\n",
    "    print(f\"  CSV loaded, total rows = {len(df)}\")\n",
    "\n",
    "    df_split = df[df[\"split\"] == split]\n",
    "    print(f\"  Rows matching split='{split}': {len(df_split)}\")\n",
    "\n",
    "    all_segments = []\n",
    "    excluded_count = 0  # track how many we exclude\n",
    "\n",
    "    for i, row in df_split.iterrows():\n",
    "        midi_rel_path = row['midi_filename']  # e.g. \"2004/MIDI-Unprocessed_XX_XX.mid\"\n",
    "        midi_abs_path = os.path.join(base_dir, midi_rel_path)\n",
    "\n",
    "        print(f\"\\n  Processing row {i}, MIDI file: {midi_abs_path}\")\n",
    "        segs = midi_to_binary_pianoroll(\n",
    "            midi_abs_path,\n",
    "            pitch_low=pitch_low,\n",
    "            pitch_high=pitch_high,\n",
    "            resolution=resolution,\n",
    "            segment_beats=segment_beats\n",
    "        )\n",
    "        valid_segments = []\n",
    "        for seg in segs:\n",
    "            # Check pitch dimension\n",
    "            if seg.shape[1] == 88:\n",
    "                valid_segments.append(seg)\n",
    "            else:\n",
    "                # Exclude the segment\n",
    "                print(f\"    Excluding segment with pitch dim={seg.shape[1]} (expected 88).\")\n",
    "                excluded_count += 1\n",
    "\n",
    "        if valid_segments:\n",
    "            print(f\"  -> {len(valid_segments)} valid segments extracted (excluded some if mismatch).\")\n",
    "        else:\n",
    "            print(\"  -> 0 valid segments extracted (possibly error or mismatch).\")\n",
    "\n",
    "        all_segments.extend(valid_segments)\n",
    "\n",
    "    print(f\"\\n*** Finished building segments for split '{split}' ***\")\n",
    "    print(f\"    Total segments = {len(all_segments)}\")\n",
    "    print(f\"    Excluded segments = {excluded_count}\\n\")\n",
    "    return all_segments\n",
    "\n",
    "\n",
    "\n",
    "def pianoroll_to_pretty_midi(\n",
    "    roll: np.ndarray,\n",
    "    pitch_low: int = 21,\n",
    "    fs: int = 24,\n",
    "    program: int = 0\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "    \"\"\"\n",
    "    Convert a binary (frames, pitch_range) roll -> a single-instrument PrettyMIDI.\n",
    "    pitch_low = the absolute MIDI pitch corresponding to roll[:,0].\n",
    "    fs = frames per second for note timing.\n",
    "    \"\"\"\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    frames, pitch_range = roll.shape\n",
    "    for p_idx in range(pitch_range):\n",
    "        pitch = pitch_low + p_idx\n",
    "        active = np.where(roll[:, p_idx] > 0.5)[0]\n",
    "        if len(active) == 0:\n",
    "            continue\n",
    "\n",
    "        # group contiguous frames\n",
    "        starts = []\n",
    "        ends = []\n",
    "        cur_start = active[0]\n",
    "        for j in range(1, len(active)):\n",
    "            if active[j] != active[j-1] + 1:\n",
    "                starts.append(cur_start)\n",
    "                ends.append(active[j-1])\n",
    "                cur_start = active[j]\n",
    "        starts.append(cur_start)\n",
    "        ends.append(active[-1])\n",
    "\n",
    "        for s, e in zip(starts, ends):\n",
    "            st_t = s / fs\n",
    "            end_t = (e+1) / fs\n",
    "            note = pretty_midi.Note(\n",
    "                velocity=100,\n",
    "                pitch=pitch,\n",
    "                start=st_t,\n",
    "                end=end_t\n",
    "            )\n",
    "            instrument.notes.append(note)\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "\n",
    "\n",
    "def save_maestro_dataset(dataset: Dataset, out_path=\"data/preprocessed_maestro.pkl\"):\n",
    "    \"\"\"\n",
    "    Saves the entire Dataset object using pickle.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    print(f\"=== Saving MaestroBinomialDiffusionDataset to: {out_path} ===\")\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        pickle.dump(dataset, f)\n",
    "    print(\"== Save complete ==\\n\")\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2) MaestroBinomialDiffusionDataset\n",
    "###############################################################################\n",
    "class MaestroBinomialDiffusionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Returns (x_noisy, x0, t) for each segment, for T steps of binomial noise.\n",
    "    \"\"\"\n",
    "    def __init__(self, segments_list, num_steps=100, ratio=None):\n",
    "        \"\"\"\n",
    "        segments_list: list of arrays shape (T, pitch_range)\n",
    "        num_steps: number of diffusion steps\n",
    "        ratio: prior ratio for binomial noise. If None, computed from data.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        print(\"\\n=== MaestroBinomialDiffusionDataset __init__ ===\")\n",
    "        print(f\"  - Received {len(segments_list)} total segments.\")\n",
    "        print(f\"  - num_steps={num_steps}, ratio={ratio}\")\n",
    "\n",
    "        self.rolls = segments_list\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "        if ratio is None:\n",
    "            print(\"  Computing average ratio of '1's across all segments...\")\n",
    "            total_ones = 0.0\n",
    "            total_size = 0.0\n",
    "            for seg in segments_list:\n",
    "                total_ones += seg.sum()\n",
    "                total_size += seg.size\n",
    "            self.ratio = total_ones / total_size\n",
    "            print(f\"  => Computed ratio: {self.ratio:.6f}\")\n",
    "        else:\n",
    "            self.ratio = ratio\n",
    "            print(f\"  Using provided ratio: {self.ratio}\")\n",
    "\n",
    "        print(\"=== Dataset initialization complete! ===\\n\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rolls) * self.num_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        roll_idx = idx // self.num_steps\n",
    "        t = idx % self.num_steps\n",
    "\n",
    "        x0 = self.rolls[roll_idx]  # shape (T, pitch_range)\n",
    "        beta_t = (t + 1) / self.num_steps\n",
    "        p_noisy = x0 * (1.0 - beta_t) + self.ratio * beta_t\n",
    "        x_noisy = np.random.binomial(1, p_noisy).astype(np.float32)\n",
    "\n",
    "        # Return shape (1, T, pitch_range) for conv2d\n",
    "        return (\n",
    "            torch.from_numpy(x_noisy).unsqueeze(0),\n",
    "            torch.from_numpy(x0).unsqueeze(0),\n",
    "            torch.tensor([t], dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16ba3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_segments = build_maestro_segments(\n",
    "#     maestro_csv=\"maestro-v3.0.0/maestro-v3.0.0.csv\",\n",
    "#     split=\"train\",\n",
    "#     pitch_low=21,\n",
    "#     pitch_high=108,\n",
    "#     resolution=24,\n",
    "#     segment_beats=16,\n",
    "#     base_dir=\"maestro-v3.0.0\"\n",
    "# )\n",
    "\n",
    "# train_dataset = MaestroBinomialDiffusionDataset(train_segments, num_steps=100, ratio=0.03)\n",
    "\n",
    "# save_maestro_dataset(train_dataset, out_path=\"data/preprocessed_maestro.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973922bd",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96eef349",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 3) MusicDiffusionGenerator (UNet-like)\n",
    "###############################################################################\n",
    "class MusicDiffusionGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified UNet architecture for binomial diffusion:\n",
    "    (batch, 1, T, pitch).  Pool only along time dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=48, channels=1, dim_mults=(1,2,4,4)):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        # MLP for time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "\n",
    "        dims = [dim*m for m in dim_mults]\n",
    "        in_chs = [channels] + dims[:-1]\n",
    "        out_chs = dims\n",
    "\n",
    "        self.downs = nn.ModuleList()\n",
    "        # We only pool time dimension => (2,1)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(2,1))\n",
    "\n",
    "        # Down path\n",
    "        for inc, outc in zip(in_chs, out_chs):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(inc, outc, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(outc, outc, 3, padding=1),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            self.downs.append(block)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(dims[-1], dims[-1], 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dims[-1], dims[-1], 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Ups\n",
    "        self.ups = nn.ModuleList()\n",
    "        reversed_in = list(reversed(dims))\n",
    "        reversed_out = reversed_in[1:] + [dims[0]]\n",
    "\n",
    "        # Only upsample time => scale_factor=(2,1)\n",
    "        self.upsample = nn.UpsamplingNearest2d(scale_factor=(2,1))\n",
    "\n",
    "        for inc, outc in zip(reversed_in, reversed_out):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(inc*2, inc, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(inc, outc, 3, padding=1),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            self.ups.append(block)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(dims[0], channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        x shape: (B, 1, T, pitch_range)\n",
    "        t shape: (B, 1)\n",
    "        Return: same shape => (B, 1, T, pitch_range)\n",
    "        \"\"\"\n",
    "        temb = self.time_mlp(t)  # (B, 128)\n",
    "        temb = temb[..., None, None]  # (B, 128, 1, 1)\n",
    "\n",
    "        skip_connections = []\n",
    "        h = x\n",
    "\n",
    "        # Down\n",
    "        for down_block in self.downs:\n",
    "            h = down_block(h)            # conv\n",
    "            skip_connections.append(h)   # store skip\n",
    "            h = self.pool(h)             # pool => time / 2, pitch stays same\n",
    "\n",
    "        # Bottleneck\n",
    "        h = self.bottleneck(h)\n",
    "\n",
    "        # Up\n",
    "        for up_block in self.ups:\n",
    "            # upsample => time *2, pitch the same\n",
    "            h = self.upsample(h)\n",
    "\n",
    "            s = skip_connections.pop()\n",
    "            # shape alignment if needed\n",
    "            if h.shape[-2:] != s.shape[-2:]:\n",
    "                min_h = min(h.shape[-2], s.shape[-2])\n",
    "                min_w = min(h.shape[-1], s.shape[-1])\n",
    "                h = h[..., :min_h, :min_w]\n",
    "                s = s[..., :min_h, :min_w]\n",
    "\n",
    "            h = torch.cat([h, s], dim=1)\n",
    "            h = up_block(h)\n",
    "\n",
    "        out = self.final_conv(h)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7ce1a",
   "metadata": {},
   "source": [
    "# Training and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1423e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 4) Training\n",
    "###############################################################################\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_diffusion_model(\n",
    "    model: nn.Module,\n",
    "    dataset: Dataset,\n",
    "    batch_size: int = 200,\n",
    "    lr: float = 5e-5,\n",
    "    epochs: int = 2,\n",
    "    device: str = \"cuda\",\n",
    "    max_steps_per_epoch: int = None  # if not None, we break after these steps\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the binomial diffusion model with L1 loss, printing logs step by step.\n",
    "    Uses tqdm for a progress bar, and optionally limits steps per epoch.\n",
    "    \"\"\"\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    print(f\"=== Initializing training ===\")\n",
    "    print(f\"  - Batch size: {batch_size}\")\n",
    "    print(f\"  - Learning rate: {lr}\")\n",
    "    print(f\"  - Epochs: {epochs}\")\n",
    "    print(f\"  - Device: {device}\")\n",
    "    print(f\"  - Dataset size: {len(dataset)}\")\n",
    "    if max_steps_per_epoch is not None:\n",
    "        print(f\"  - Will stop each epoch after {max_steps_per_epoch} steps\\n\")\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.L1Loss()\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n>>> Starting epoch {epoch+1}/{epochs} <<<\")\n",
    "        # Wrap the dataloader in tqdm:\n",
    "        loader = tqdm(dataloader, desc=f\"Epoch {epoch+1}\", total=len(dataloader))\n",
    "        total_loss = 0.0\n",
    "        step_count = 0\n",
    "\n",
    "        for x_noisy, x0, t in loader:\n",
    "            x_noisy = x_noisy.to(device)\n",
    "            x0      = x0.to(device)\n",
    "            t       = t.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            x0_pred = model(x_noisy, t)\n",
    "\n",
    "            loss = loss_fn(x0_pred, x0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step_count += 1\n",
    "\n",
    "            # Update tqdm info\n",
    "            loader.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "            # If you want to cut short each epoch, do so here:\n",
    "            if max_steps_per_epoch is not None and step_count >= max_steps_per_epoch:\n",
    "                print(f\"  Stopped epoch {epoch+1} after {max_steps_per_epoch} steps (early break).\")\n",
    "                break\n",
    "\n",
    "        avg_loss = total_loss / step_count\n",
    "        print(f\"==> Epoch {epoch+1} finished. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"\\n=== Training complete! ===\\n\")\n",
    "    return model\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5) Sampling with XOR + Mask\n",
    "###############################################################################\n",
    "def sample_binomial_diffusion(\n",
    "    model: nn.Module,\n",
    "    shape=(384, 88),\n",
    "    total_steps: int = 100,\n",
    "    ratio: float = 0.03,\n",
    "    device: str = \"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced sampling, step by step:\n",
    "      1) Start from pure binomial noise p=ratio\n",
    "      2) For t in [T..1]:\n",
    "         - predict x0\n",
    "         - binarize x0\n",
    "         - XOR with original xT\n",
    "         - partial revert with mask\n",
    "    Returns a final numpy array shape=(T, pitch_range).\n",
    "    \"\"\"\n",
    "    print(\"=== Starting sampling process ===\")\n",
    "    print(f\"  - shape={shape}, total_steps={total_steps}, ratio={ratio}, device={device}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 1) create binomial noise\n",
    "        xT_np = np.random.binomial(1, ratio, size=shape).astype(np.float32)\n",
    "        print(\"  Generated initial binomial noise...\")\n",
    "\n",
    "        x_current = torch.from_numpy(xT_np).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        xT_tensor = x_current.clone()\n",
    "\n",
    "        # 2) iterative\n",
    "        for i in range(total_steps):\n",
    "            t_val = total_steps - i - 1\n",
    "            if i % 10 == 0:\n",
    "                print(f\"  Sampling step: {i+1}/{total_steps}, t_val={t_val}\")\n",
    "\n",
    "            t_tensor = torch.tensor([[t_val]], dtype=torch.float32, device=device)\n",
    "            x0_pred = model(x_current, t_tensor)\n",
    "            x0_bin = (x0_pred >= 0.5).float()\n",
    "\n",
    "            delta = (xT_tensor != x0_bin).float()\n",
    "            beta = (t_val + 1) / total_steps\n",
    "            mask = torch.bernoulli(delta * beta)\n",
    "\n",
    "            x_current = x0_bin * (1 - mask) + xT_tensor * mask\n",
    "\n",
    "        final_roll = x_current.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    print(\"=== Sampling complete! Returning final roll. ===\\n\")\n",
    "    return final_roll\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 6) Save & Play\n",
    "###############################################################################\n",
    "def sample_pianoroll_and_save_midi(\n",
    "    model: nn.Module,\n",
    "    out_midi=\"generated_sample.mid\",\n",
    "    shape=(384, 88),\n",
    "    total_steps=100,\n",
    "    ratio=0.03,\n",
    "    pitch_low=21,\n",
    "    device=\"cuda\",\n",
    "    out_dir=\"experiments\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Sample from the diffusion model\n",
    "    2) Convert to MIDI\n",
    "    3) Save MIDI to disk inside out_dir (default: experiments)\n",
    "    4) Return (roll, out_midi_path)\n",
    "    \"\"\"\n",
    "    print(\"=== sample_pianoroll_and_save_midi ===\")\n",
    "    print(f\"  - Output MIDI filename: {out_midi}\")\n",
    "    print(f\"  - shape={shape}, total_steps={total_steps}, ratio={ratio}, pitch_low={pitch_low}\")\n",
    "    print(f\"  - Saving to directory: {out_dir}\\n\")\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    roll = sample_binomial_diffusion(\n",
    "        model=model,\n",
    "        shape=shape,\n",
    "        total_steps=total_steps,\n",
    "        ratio=ratio,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print(\"  Converting final roll to PrettyMIDI object...\")\n",
    "    pm = pianoroll_to_pretty_midi(roll, pitch_low=pitch_low, fs=24)\n",
    "\n",
    "    out_path = os.path.join(out_dir, out_midi)\n",
    "    pm.write(out_path)\n",
    "    print(f\"  MIDI saved to: {out_path}\\n\")\n",
    "\n",
    "    return roll, out_path\n",
    "\n",
    "\n",
    "def generate_and_play_audio_from_model(\n",
    "    model: nn.Module,\n",
    "    out_name=\"sample_01\",\n",
    "    shape=(384, 88),\n",
    "    pitch_low=21,\n",
    "    ratio=0.3,\n",
    "    total_steps=100,\n",
    "    device=\"cuda\",\n",
    "    out_dir=\"experiments\",\n",
    "    fs=44100\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a sample from the model, saves the MIDI, converts to WAV,\n",
    "    and returns an Audio object to play in the notebook.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"üéº Generating sample: {out_name}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Sample piano roll\n",
    "    roll = sample_binomial_diffusion(\n",
    "        model=model,\n",
    "        shape=shape,\n",
    "        total_steps=total_steps,\n",
    "        ratio=ratio,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"  ‚úÖ Roll generated. Shape: {roll.shape}, Sum: {roll.sum()}\")\n",
    "\n",
    "    # Step 2: Convert to PrettyMIDI\n",
    "    pm = pianoroll_to_pretty_midi(roll, pitch_low=pitch_low, fs=24)\n",
    "\n",
    "    # Step 3: Save MIDI\n",
    "    midi_path = os.path.join(out_dir, f\"{out_name}.mid\")\n",
    "    pm.write(midi_path)\n",
    "    print(f\"  üíæ MIDI saved to: {midi_path}\")\n",
    "\n",
    "    # Step 4: Convert to WAV using fluidsynth\n",
    "    try:\n",
    "        audio = pm.fluidsynth(fs=fs)\n",
    "        wav_path = os.path.join(out_dir, f\"{out_name}.wav\")\n",
    "        write(wav_path, fs, audio.astype(np.int16))\n",
    "        print(f\"  üîä WAV saved to: {wav_path}\")\n",
    "\n",
    "        # Step 5: Return playable audio\n",
    "        return ipd.Audio(wav_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to synthesize audio: {e}\")\n",
    "        print(\"You may need to install `fluidsynth`. Try: pip install pyfluidsynth\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c87e71",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc23daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading MaestroBinomialDiffusionDataset from: data/preprocessed_maestro.pkl ===\n",
      "== Load complete, dataset has 3539500 items ==\n",
      "\n",
      "Dataset loaded, length: 3539500\n",
      "Subset length: 5000\n"
     ]
    }
   ],
   "source": [
    "def load_maestro_dataset(in_path=\"preprocessed_maestro.pkl\"):\n",
    "    \"\"\"\n",
    "    Loads the Dataset object from pickle.\n",
    "    \"\"\"\n",
    "    print(f\"=== Loading MaestroBinomialDiffusionDataset from: {in_path} ===\")\n",
    "    with open(in_path, \"rb\") as f:\n",
    "        ds = pickle.load(f)\n",
    "    print(f\"== Load complete, dataset has {len(ds)} items ==\\n\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "maestro_dataset = load_maestro_dataset(\"data/preprocessed_maestro.pkl\")\n",
    "print(\"Dataset loaded, length:\", len(maestro_dataset))\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Let's pick the first 50k samples\n",
    "subset_indices = list(range(5000))\n",
    "\n",
    "# Create a Subset\n",
    "maestro_subset = Subset(maestro_dataset, subset_indices)\n",
    "print(\"Subset length:\", len(maestro_subset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594f8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = MusicDiffusionGenerator(dim=48, channels=1, dim_mults=(1,2,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd729c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initializing training ===\n",
      "  - Batch size: 256\n",
      "  - Learning rate: 0.0001\n",
      "  - Epochs: 1\n",
      "  - Device: cuda:1\n",
      "  - Dataset size: 5000\n",
      "  - Will stop each epoch after 2000 steps\n",
      "\n",
      "\n",
      ">>> Starting epoch 1/1 <<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:48<00:00,  2.43s/it, loss=0.0762]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 1 finished. Average Loss: 0.0897\n",
      "\n",
      "=== Training complete! ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train, limiting each epoch to 2k steps, so we can do a quick test:\n",
    "model = train_diffusion_model(\n",
    "    model,\n",
    "    maestro_subset,\n",
    "    batch_size=256,\n",
    "    lr=1e-4,\n",
    "    epochs=1,\n",
    "    device=device,\n",
    "    max_steps_per_epoch=2000  # remove or set None to use the full epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0f4687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéº Generating sample: my_music_sample\n",
      "=== Starting sampling process ===\n",
      "  - shape=(384, 88), total_steps=100, ratio=0.3, device=cuda:1\n",
      "  Generated initial binomial noise...\n",
      "  Sampling step: 1/100, t_val=99\n",
      "  Sampling step: 11/100, t_val=89\n",
      "  Sampling step: 21/100, t_val=79\n",
      "  Sampling step: 31/100, t_val=69\n",
      "  Sampling step: 41/100, t_val=59\n",
      "  Sampling step: 51/100, t_val=49\n",
      "  Sampling step: 61/100, t_val=39\n",
      "  Sampling step: 71/100, t_val=29\n",
      "  Sampling step: 81/100, t_val=19\n",
      "  Sampling step: 91/100, t_val=9\n",
      "=== Sampling complete! Returning final roll. ===\n",
      "\n",
      "  ‚úÖ Roll generated. Shape: (384, 88), Sum: 103.0\n",
      "  üíæ MIDI saved to: experiments/my_music_sample.mid\n",
      "‚ö†Ô∏è Failed to synthesize audio: fluidsynth() was called but pyfluidsynth is not installed.\n",
      "You may need to install `fluidsynth`. Try: pip install pyfluidsynth\n"
     ]
    }
   ],
   "source": [
    "# Sample + playback\n",
    "audio_obj = generate_and_play_audio_from_model(\n",
    "    model=model,\n",
    "    out_name=\"my_music_sample\",\n",
    "    shape=(384, 88),\n",
    "    pitch_low=21,\n",
    "    ratio=0.3,\n",
    "    total_steps=100,\n",
    "    device=device,\n",
    "    out_dir=\"experiments\"\n",
    ")\n",
    "\n",
    "if audio_obj:\n",
    "    display(audio_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e666acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI end time: 15.915909090909091\n",
      "Number of notes: 103\n"
     ]
    }
   ],
   "source": [
    "pm = pretty_midi.PrettyMIDI(\"experiments/my_music_sample.mid\")\n",
    "print(\"MIDI end time:\", pm.get_end_time())\n",
    "print(\"Number of notes:\", sum(len(i.notes) for i in pm.instruments))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi_giorgio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
